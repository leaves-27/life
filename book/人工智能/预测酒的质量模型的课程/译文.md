在这个端到端的pyhon机器学习教程中，你将学习如何用Scikit-learn构建和校正一个监督学习模型。

我们将根据酸性、含糖量和酒精浓度的特征训练和校正一个自由森林用来预测红酒的质量。

开始前，我们应该说明下，这个课程是为对应用机器学习感兴趣的初学者打造的。

我们的目标是向你介绍python中用于机器学习的一个最灵活且最有用的库。

## 我们开始前的题外话
### 前提条件

开始学习这个教程的推荐前提条件是要求你至少具备基本的Python编程技能。为了快速的开始，我们假设你已经有了这个背景。

## python机器学习教程的内容
这儿是用Scikit-Learn构建你的第一个自由森林模型的步骤：
1.搭建你的环境
2.导入相关库和模块
3.加载红酒数据
4.拆分数据为训练数据和测试数据
5.确定数据预处理步骤
6.确定要校正的超参数
7.用交叉验证管道校正模型
8.在整个训练数据集上调试
9.在测试数据上评估模型管道
10.为了将来使用保存模型

### 步骤1：搭建你的环境
首先，拿一杯醇香的红酒。
下来，确保下面的东西被在你的电脑上安装了。

- Python 2.7+ or Python 3
- NumPy
- Pandas
- Scikit-Learn (a.k.a. sklearn)

我们强烈推荐通过Anaconda安装Python。因为它自带安装了上面提到的所有包。

如果你想要更新某些包，它和在命令行中输入conda update <package>(在苹果电脑下面的终端)一样简单。

你可以像这样确认Scikit-Learn已经被正确的安装了：

```
	python -c "import sklearn; print sklearn.__version__"
	0.18.1
```

好了，现在让我们开始新建一个新的文件，然后把它命名为sklearn_ml_example.py	

### 步骤2：导入库和模块
开始，让我们导入numpy，其为更高效的数值计算提供了支持。

```
import numpy as np
```
接着，我们将导入Pandas，一个支持dataframes的实用库。Pandas严格来说是可选的，因为Scikit-Learn可以直接操作数据矩阵，但是它可以使我们的操作更容易。
```
import pandas as pd
```
现在，是时候开始导入机器学习函数了。第一个函数是来自model_selection模块的train_test_split()函数。正如他的名字暗示的那样，这个模块包含许多功能。它将帮助我们在模型之间进行选择。
```
from sklearn.model_selection import train_test_split
```
下一步，我们将导入整个预处理模块。它包含缩放、转换和包装数据的功能。

```
from sklearn import preprocessing
```
下一步，让我们导入我们将需要的模型家族...等等，你刚刚说“家族”？

模型家族和真实的模型直接有什么不同？

模型家族是模型类型的统称。例如，自由森林，SVM's,线性回归模型等等。在每个模型家族内，你对数据进行调试和校正它的参数后，你将得到一个真实的模型。

我们可以像这样导入自由森林家族：  
```
from sklearn.ensemble import RandomForestRegressor
```
限于这个教程的篇幅，我们将仅仅聚焦于训练自由森林和校正它的参数。对于在模型家族之间如何选择，我们将在另一篇教程中详述。  

现在，让我们看看导入帮助我们执行交叉验证的工具。
```
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import GridSearchCV
```

接下来，让我们导入一些衡量指标，后面我们可以用来评估我们的模型性能。  
```
from sklearn.metrics import mean_squared_error, r2_score
```

最后，我们将导入一个用来保留我们的模型为以后使用的方法。  
```
from sklearn.externals import joblib
```

Joblib对于python的pickle包来说是可选的，但因为它对于存储巨大的numpy数组更有效，所以我们将用它。  

唷，内容真多。不要担心，在这里我们只是简单看一下，我们将在详情中具体讲解每一个函数。让我们先喝一小口红酒、吃一小口面包....干杯。

### 步骤3：加载红酒数据
好了，现在我们准备加载我们的数据。我们导入的拥有一整套有用的输入输出工具的Pandas库已经被加载。  

你可以从CSV、EXCEL、SQL、SAS和许多其他数据格式中读取数据。这儿是所有Pandas库输入输出工具的一个清单：http://pandas.pydata.org/pandas-docs/stable/io.html。

今天我们将使用的实用工具是read_csv()函数。使用这个函数，我们可以加载一些CSV文件，即使是从一个远程URL!  

现在让我们看看这个数据的前五行。  

糟糕...这个看起来真凌乱。仔细看看，这个CSV文件好像是用分号对数据进行了分隔。它是令人讨厌的，但是很容易被解决：代码样例。
 
很好，这个看起来就非常清晰了。现在，让我们一起看看这个数据。  

我们有1599个样本和12个特征(包括我们的目标特征)。我们可以容易的打印出一些大概的统计数据。  

这儿是所有特征的列表：一个列表。  

所有特征都是数字类型，很简单。然而，它们的尺度范围完全不一样，我们先努力记住到后面的标准化数据再看。  

提醒一下，我们砍掉了许多我们通常推荐的预数据分析。 
 
从现在开始，让我们开始拆分数据。

### 步骤4：拆分数据为训练数据和测试数据
在你的建模工作流开始时，把数据拆分为训练数据和测试数据对得到你的模型执行更接近真实情况是至关重要的。  

首先，让我们从你的输入特征中分离出我们的目标特征：代码样例   

然后拆分数据允许我们利用Scikit-Learn的train_test_split函数来进行拆分：代码样例    

像你看到的那样，我们将数据的20%作为评估我们模型的测试数据集。我们也可以随意设置一个状态，以便我们可以重复生成我们的结果。    

最后，根据目标变量把我们的样例进行分层是一个很好的练习。它将确保你的训练数据看起来和你的测试数据类似，使你的评估指标更可靠。  


### 步骤5：确定数据预处理的步骤
回忆一下在步骤3中，因为各特征的数值是在不同的区间上的，所以我们默记了下标准化我们的特征。

什么是标准化？
标准化是从每个特征减去均值然后根据特征的标准差划分它们的过程。

标准化是机器学习任务的一个常见必备技能。许多算法假设所有特征以0为中心且有大概相同的波动。

首先声明下，这儿是我们后面将不会使用的代码

Scikit-Learn使数据预处理变的非常简单。例如，简单的调整数据的波动区间是非常容易的。

你可以看到这个调整数据范围后的数据集一定是以0为中心且有相同的波动。

非常好，但是我们为什么说我们不用这个代码？

原因是在测试数据上，我们不可能执行完全相同的转换。
然而，我们仍然可以单独的调整测试数据的尺度。但是不用我们曾经转换训练数据那样的平均值和标准方差的方法。

换句话说，那种处理方法对模型如何锤炼、预处理、以及在新数据上执行不是一种公平的处理方法。

现在，这儿是我们将使用的预处理代码：   

代替直接调用这个尺度函数，我们将用一个在Scikit-Learn中被叫做转换器 API的功能。这个转换器api允许你安装一个在使用训练数据时采用年的相同的方式的预处理步骤。然后在将来的数据上用这个相同的转换。

这儿是这个过程看起来的样子：  

1.在训练数据上安装这个转换器    
2.应用这个转换器到训练数据   
3.应用这个转换器到测试数据  

这个使你最终的模型执行更接近于实际，它允许插入你的预处理步骤到交叉验证管道。

这儿是你要如何实际来做：

```
scaler = preprocessing.StandardScaler().fit(X_train)
```

现在，Scaler对象已经有保存的平均值并且对训练数据中的每一个特征进行了标准方差。

让我们一起看看它工作:
```
X_train_scaled = scaler.transform(X_train)
 
print X_train_scaled.mean(axis=0)
print X_train_scaled.std(axis=0)

```
记下我们如何拿到这个Scaler对象并且如何用它转换做这个训练数据集。后面，我们可以用这个曾经转换训练数据集的相同平均值和标准方差来转换测试数据集。

注意在测试数据集上缩放后的特征不完全拥有相同的偏差以0为中心。这是像我们期望的准确的样子，因为我们用来自训练数据集的平均值来转换测试数据集，而不是来自测试数据集它本身。

在实际中，当我们创建交叉管道时，我甚至不需要手动地安装转换API。而是简单的像如下这样声明这个类对象就好了:

这是它看起来准确的样子：

使用StandardScaler方法先转换数据的一个模型管道，然后安装一个使用了自由森林回归的模型

### 步骤6：确定要校正的超参数
现在是时候考虑我们想要为我们的模型校正的超参数了。

超参数是什么？

我们需要考虑的有两种类型的参数：模型参数和超参数。模型参数可以被从数据中直接学习，而超参数不能。

超参数表示关于模型更高级别的结构信息,它们需要在训练这个模型前被设置.

例如：自由森林超参数

作为一个例子，让我们为回归任务拿我们的自由森林来讨论：

在每个决策树里面，计算机可以基于MSE(均方误差)或MAE(平均绝对误差)靠经验决定在哪个地址创建分支。因此，这个真实的分支位置是模型参数。

然而，算法不知道两个准则的哪一个MSE还是MAE应该被使用。算法也不能决定在这个森林里面有多少棵树。这些就是使用者必须设置超参数的例子。

我们可以像这样列出可供校正的超参数:图例

你也可以在自由森林回归文档上找到所有参数的一个列表。请注意，通过一个管道校正时，你将需要像在上面的代码中那样，在参数命名前预先追加randomforestregressor__

现在，让我们确定我们想要通过交叉验证校正的超参数。

正如你看到的，这个格式应该是一个Python字典(键值对的数据结构).键是超参数的名字，值是尝试设置的一个列表。参数值的可选值可以被在文档上找到。

### 步骤7：用交叉验证管道校正模型
现在我们几乎已经准备好深入装配我们的模型了。但是首先，我们应该花费一些时间谈一下交叉验证。

在所有机器学习的技巧中这是最重要的技巧之一。因为它帮助你最大化模型的执行性能的同时减少了过渡拟合的风险。

什么是交叉验证？

交叉验证是一个为可靠的评估一个方法(通过用相同的方法训练和多次评估你的模型来构建一个模型的方法)的性能的过程。


实际上，那个方法是在当前上下文中简单的一组超参数。
这些是交叉验证的步骤:
1.拆分你的数据为k等份(一般拆分为10份)。
2.在k-1份上训练你的模型。
3.在保留的那一份上评估它(例如第10份)。
4.执行第2步和第三步k次，每次保留一个不同的相等份。
5.根据所有k相等份来计算性能。这是你的性能指标。

在机器学习中，为什么交叉验证是重要的？

让我们假设你想要训练一个自由森林回归模型。你必须校正的超参数中的一个是在你的森林中每个决策树允许的最大深度。

你如何确定？

这正是交叉验证的用武之地。仅仅使用你的训练集，你可以用交叉验证评估不同的超参数和估算他们的有效性。
这允许你保持你的测试集未被训练，当你最终准备好选择一个模型时，为一个真实的保留相等份评估保存它。

例如，你可以用交叉验证校正一个真自由森林模型,一个线性的回归模型，一个k近邻模型，仅仅使用训练数据集。然后你仍然有这个未被训练的测试集来在模型家族之间做你的最终选择。

那交叉验证管道又是什么？

当你执行验证时最好的做法是在交叉验证循环里面包含你的数据预处理步骤。这样可以预防偶然的用来自测试相等份的重要数据污染你的训练相等份。

这儿是包含了预处理步骤后，这个交叉验证管道如何运行的样子：
1.拆分你的数据为k等份(一般拆分为10份)。
2.预处理k-1训练等份。
3.在k-1份上训练你的模型。
4.用来自步骤2的相同改变预处理保留等份。
5.在保留的那一份上评估它(例如第10份)。
6.执行第2步和第三步k次，每次保留一个不同的相等份。
7.根据所有k相等份来计算性能。这是你的性能指标。

幸运的是，Scikit-Learn使它运行起来很简单。

```
clf = GridSearchCV(pipeline, hyperparameters, cv=10)
 
# Fit and tune model
clf.fit(X_train, y_train)
```

是的，它是真的很容易。GridSearchCV本质上执行交叉验证是通过超参数的完整表格(所有可能的排列组合)来执行。

在你的模型中，它用到了你想要校正的超参数、创造的等份的数量(在本例中，我们使用了一个模型管道)。

很显然，在幕布之下，有很多事情。我们已经包括了的上面的假代码，在独立的教程的部分中，我们将重写交叉验证部分。

现在，你可以看看用交叉验证找到的最后的参数设置。

```
print clf.best_params_
# {'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'auto'}
```

想不到的是，它看起来像是默认参数。
### 步骤8：在整个训练数据上使用

### 步骤9：在测试数据上评估管道模型

### 步骤10: 为将来使用保存这个模型





























