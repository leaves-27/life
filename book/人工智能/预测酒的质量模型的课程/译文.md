在这个端到端的pyhon机器学习教程中，你将学习如何用Scikit-learn构建和校正一个监督学习模型。

我们将根据酸性、含糖量和酒精浓度的特征训练和校正一个自由森林用来预测红酒的质量。

开始前，我们应该说明下，这个课程是为对应用机器学习感兴趣的初学者打造的。

我们的目标是向你介绍python中用于机器学习的一个最灵活且最有用的库。

## 我们开始前的题外话
### 前提条件

开始学习这个教程的推荐前提条件是要求你至少具备基本的Python编程技能。为了快速的开始，我们假设你已经有了这个背景。

## python机器学习教程的内容
这儿是用Scikit-Learn构建你的第一个自由森林模型的步骤：
1.创建你的环境
2.导入库和模块
3.加载红酒数据
4.拆分数据为训练数据和测试数据
5.数据预处理步骤
6.校正超参数
7.用交叉验证管道校正模型
8.在整个训练数据上重新安装
9.在测试数据上评估管道模型
10.为将来使用保存模型

### 步骤1：创建你的环境
首先，拿一杯红酒。
下来，确保下面的东西被在你的电脑上安装。

- Python 2.7+ or Python 3
- NumPy
- Pandas
- Scikit-Learn (a.k.a. sklearn)

我们强烈推荐通过Anaconda安装Python。因为这样上面列的所有包将和它一起被安装。

如果你想要更新包中的一些，它和在命令行中输入conda update <package>(在苹果电脑下面的终端)一样简单。

你可以像这样确认Scikit-Learn已经被安装了：

```
	python -c "import sklearn; print sklearn.__version__"
	0.18.1
```

好了，现在让我们开始新建一个新的文件，然后把它命名为sklearn_ml_example.py	

### 步骤2：导入库和模块
开始，让我们导入numpy，其为高效的数值计算提供支持。

```
import numpy as np
```
下来，我们将导入Pandas，一个支持dataframes的实用库。Pandas技术上来说是可选的，因为Scikit-Learn可以直接操作数据矩阵，但是它可以使我们的操作更容易。
```
import pandas as pd
```
现在，是时间开始导入机器学习函数了。第一个函数是来自model_selection模块的train_test_split()函数。正如他的名字暗示的那样，这个模块包含许多功能。它将帮助我们在模型之间进行选择。
```
from sklearn.model_selection import train_test_split
```
下一步，我们将导入整个预处理模块。它包含缩放、转换和包装数据的功能。

```
from sklearn import preprocessing
```
下一步，让我们导入我们将需要的模型家族...等等，你刚刚说“家族”？

模型家族和真实的模型直接有什么不同？

模型家族是模型类型的统称。例如，自由森林，SVM's,线性回归模型等等。在每个模型家族内，你对数据安装和调整它的参数后，你将得到一个真实的模型。

我们可以像这样导入自由森林家族：  
```
from sklearn.ensemble import RandomForestRegressor
```
限于这个教程的篇幅，我们将仅仅聚焦于训练自由森林和调整它的参数。对于在模型家族之间如何选择，我们将在另一篇教程中详述。  

现在，让我们看看导入帮助我们执行交叉验证的工具。  
```
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import GridSearchCV
```

接下来，让我们导入后面我们可以评估我们的模型性能的指标。  
```
from sklearn.metrics import mean_squared_error, r2_score
```

最后，我们将导入一个用来保留我们的模型为以后使用的方法。  
```
from sklearn.externals import joblib
```

Joblib对于python的pickle包来说是可选的。因为它对于存储巨大的numpy数组更有效，所以我们将用它。  

唷，内容真多。不要担心，我们将在详情中具体讲解每一个函数，这里我们只是简单看一下。  

### 步骤3：加载红酒数据 
好了，现在我们准备加载我们的数据。我们导入的拥有一整套有用的输入输出工具的Pandas库已经被加载。  

你可以从CSV,EXCEL,SQL,SAS和许多其他数据各种中读数据。这儿是所有Pandas库输出输出工具的一个清单：http://pandas.pydata.org/pandas-docs/stable/io.html。

今天我们将使用的实用工具是read_csv()函数。使用这个函数，我们可以加载一些CSV文件，即使是从一个远程URL!  

现在让我们看看这个数据的前五行。  

糟糕...这个看起来真凌乱。仔细看看，这个CSV文件好像是用你分号对数据进行了分隔。它是令人讨厌的，但是很容易被解决：代码样例  
 
很好，这个看起来非常清晰。现在，让我们一起看看这个数据。  

我们有1599个样本和12个特征(包括我们的目标特征)。我们可以容易的打印出一些大概的统计数据。  

这儿是所有特征的列表：一个列表。  

所有特征都是数字类型，很简单。然而，它们有一些非常不一样的尺度范围，我们先努力记住到后面的标准化数据再看。  

提醒一下，我们砍掉了许多我们通常推荐的预数据分析。  
 
从现在开始，让我们开始拆分数据。  


### 步骤4：拆分数据为训练数据和测试数据  
在你的建模工作流开始时，把数据拆分为训练数据和测试数据对得到你的模型执行更接近真实情况是至关重要的。  

首先，让我们从你的输入特征中分离出我们的目标特征：代码样例   

然后拆分数据允许我们利用Scikit-Learn的train_test_split函数来进行拆分：代码样例    

像你看到的那样，我们将数据的20%作为评估我们模型的测试数据集。我们也可以随意设置一个状态，以便我们可以重复生成我们的结果。    

最后，根据目标变量把我们的样例进行分层是一个很好的练习。它将确保你的训练数据看起来和你的测试数据类似，使你的评估指标更可靠。  


### 步骤5：声明数据预处理步骤
回忆一下在步骤3中，因为各特征的数值是在不同的尺度范围上的，所以我们努力记忆了下标准化我们的特征。

什么是标准化？
标准化是从每一个特征中减去一个部分的过程，然后通过特征的标准分差划分它们。

标准化是机器学习任务的一个常见前提条件。许多算法假设所有特征以0为中心且有大概相同的波动。

首先声明下，这儿是我们后面将不会使用的代码

Scikit-Learn使数据预处理变的非常简单。例如，简单的调整数据的范围是非常容易的。

你可以看到这个调整数据范围后的数据集一定是以0为中心且有相同的波动。

非常好，但是我们为什么说我们不用这个代码？

原因是在测试数据上，我们不可能执行完全相同的转换。
然而，我们仍然可以单独的调整测试数据的尺度。但是不用我们曾经转换训练数据那样的means和标准方差的方法。

换句话说，那个对模型如何锤炼、预处理、以及在新数据上执行不是一种公平的形式。

现在，这儿是我们将使用的预处理代码：   

代替直接调用这个尺度函数，我们将用一个在Scikit-Learn中被叫做转换器 API的功能。这个转换器api允许你安装一个在使用训练数据时采用年的相同的方式的预处理步骤。然后在将来的数据上用这个相同的转换。

这儿是这个过程看起来的样子：  

1.在训练数据上安装这个转换器   
2.应用这个转换器到训练数据  
3.应用这个转换器到测试数据  

### 步骤6：声明要校正的超参数
### 步骤7：用交叉验证校正模型
### 步骤8：在整个训练数据上使用
### 步骤9：在测试数据上评估管道模型
### 步骤10: 为将来使用保存这个模型





























