嘿 Leaves-27,我们已经完成了这个速成课程的一半。
非常漂亮，让我们保持继续...许多优秀的内容在第二个半节。
昨天，你已经学习了一个用来清洗数据集的可靠主体结构。

让我们揭晓下昨天的小测验的答案。

1.介绍
特征管理是从已经存在的特征中创建新的输入特征。
它是数据科学工作者所做的用来提高数据模型性能最有价值的任务之一。
它能提高数据模型性能的原因是：
  你分离、突出的关键信息，可以让你的算法集中在重要的东西上。
  你可以融入你自己的专业知识。
  更重要的是，一旦你理解透彻了特征管理，你可以融入其他人的专业知识！

在这一课中，我们将介绍几个启发理论帮助你激发新的想法。
在继续之前，我们自己罗列一下特征管理的纲要，因为对这一步来说有无限的可能性。
好消息是由于你获得了足够多的经验，这个技巧可以很自然而然的提高。

2.行业知识

你可能常常通过融入你的行业知识或其他人的行业知识来管理有价值的特征。
试着想一想你想要分离的特定信息。这里你有许多创新的自由。

回到我们的不动产数据集，让我们假设你记得在一段时间内出现了住房危机。
那么好了，如果你怀疑住房危机可能会对住房价格造成影响，那么你可以为那段时间内的住房交易创造一个指标变量。这个指标变量是一个值为0或1的二元变量。它们表明一个观察对象遇到一个特定的条件的结果，它们对分离关键特征是非常有用的。

正如你可能猜测的那样，行业知识是非常宽泛的。在某一点，你可能被卡住。
解决办法是下面的部分要讲的。有一些特定的方法可以帮助你突破它想到新的方法。

3.相互影响特征

启发理论的第一个是检查看看你是否可以创建一些便于理解的相互影响特征。它是两个或者更多特征的结合。

顺便说一下，在一些情景下，相互影响项一定是两个变量的乘积。在我们的课程中，相互关联的特征可能是两个特征的乘积、和或者差。
回到我们的不动产例子：
  让我们假设我们已经有一个被叫做"num_schools"的特征，例如，5英里内的学校数。让我们假设我们也有一个被叫做'median_school'的特征，例如，那些学校的平均质量得分。
  然而，我们可能猜想，真正重要的是还有许多学校可选，但他们已经很好了。

好了，捕捉相互关系，我们可以简单的创建一个新的特征'，school_score' = 'num_schools' * 'median_school'。

常见的小窍门是看看每一对特征并且问自己，‘我可以用一些更有用的方法合并这个信息吗？

4.稀有种类

下来我们要看的方法是将稀有种类进行分组。
稀有种类是那些总观察对象非常少的种类。它们对于一些机器学习算法是有问题的，会引起模型的过度拟合等等。
多少种类编为一组没有正式的规定。
它依赖于你的数据集的大小和你拥有的其他特征的数量。
作为一般的处理原则，我们推荐合并种类直到每一个类有至少50个观察对象。和一般的处理原则一样，这个仅仅是作为一种指导原则（而不是真的作为一个法定规则）。

让我们再来看看不动产例子：

好了，我们把相似的种类分为一组。在上面的图表中，'exterior_walls'特征有几个非常相似的种类。'Wood Siding', 'Wood Shingle',和'Wood'，我们可以把它们分为一组，形成一个单独的种类。事实上，我们仅仅是把它们都标记为'Wood'。接下来，我们可以把剩下的稀有种类划分到'Other'种类中，即使我们已经有一个'Other'种类。我们把'Concrete Block', 'Stucco', 'Masonry', 'Other', 和'Asbestos shingle'划分进'Other'种类。

这儿是合并相似的和其他的种类后，这个分类的分布：<img />

合并稀有种类后，我们剩下的唯一性种类更少了，但是每个种类有了更多的观察对象。
通常，一个小小的测试足以决定你是否对某些种类进行分组。

5.模拟变量

许多机器学习算法不能直接操作分类的特征。特别是，对于文本值。因此，我们需要为我们的分类特征创建一些模拟变量。

模拟变量是一系列二元变量，每一个二元变量代表来自一个分类的特征的单个分类。它代表的信息和分类的特征是等价的，但是这个数值允许你根据算法的需要传递。

在上面的例子上，对稀有种类进行分组后，我们少了8个种类，他们转化成8个模拟变量如下：


6.移除无用的特征
最后，从数据集移除无用的或者不相干的特征。

无用的特征是那些我们的机器学习算法不能理解的那些。例如包括：
  ID项
  对预测没有用的特征
  一些文本描述

不相干的特征通常是那些可以被你在特征管理期间添加的其他的特征替换的特征

7.结论
 完成数据清洗和特征管理后，你将把你的原数据转化成一个基于表格的可用于进行分析的数据。
 我们叫它‘ABT’因为它是你将在之上构建你的模型的东西。

 作为最后的一个小敲门：
   不是所有你管理的特征都需要计入。事实上，你常常会发现他们中的许多不会增强你的模型。那是正常的，因为一个精准的预测特征足以抵消 10个无用的特征。

选择机器学习算法的关键是在大量选项（内建的特征选择）中可以自动选择最好的特征。

它允许你避免过渡拟合你的模型，尽管有多个输入特征。

好了，到现在你知道了这个金刚钻。到测验时间了！
  指标变量是什么？他们为什么有用？
  你可以用来对稀有种类进行分组的两个标准是什么？
  在从相同的特征创建的一组模拟变量中，多个变量的值可以是1吗？
  在我们的不动产例子中，如果你特征有金属墙，'exterior_walls'模拟变量的值是什么？
  
明天，我们将深入看看算法选择，为了找出最有用的算法，给你我们的推荐做法。